# Databricks notebook source
# MAGIC %md
# MAGIC # DLT Flows

# COMMAND ----------

# MAGIC %md
# MAGIC #### Load libraries and functions
# MAGIC

# COMMAND ----------

import dlt
from databricks.sdk.runtime import spark
from pyspark.sql import functions as F

# COMMAND ----------

dlt.create_streaming_table(
    name="{{table_name}}", comment="Clean, merged data", table_properties={"quality": "silver"}
)


@dlt.table(name="{{table_name}}")
def dynamic_flow_{{table_name}}() -> dlt.DataFrame:
    """Dynamic flow for the {{table_name}} table."""
    return spark.readStream.table("hive_metastore.aldm_staging.{{table_name}}")
